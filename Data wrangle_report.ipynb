{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I gathered, assessed, and cleaned data, then I acted on it through analysis, and visualization. The dataset I wrangled (and analyzed and visualized) is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage.\n",
    "\n",
    "### Step 1: Gathering Data\n",
    "In order to create my Consumer API credentials, Access Token, and Access Token Secret, I created a Twitter developer account. These are necessary in order to use the \"Tweepy\" to access Twitter's API, query Twitter for each tweet's JSON data, and store the whole set of JSON data for each tweet in a file called tweet json.txt. Each tweet's JSON data was written to a separate line. In a pandas DataFrame with variables for \"tweet id,\" \"retweet count,\" \"favorite count,\" \"display text range,\" \"lang,\" and \"created at,\" I then read this.txt file line by line.\n",
    "\n",
    "### Step 2: Assessing Data\n",
    "After gathering all three pieces of data, I assessed them visually and programmatically for quality and tidiness issues. I Detected and documented the quality issues and tidiness issues.\n",
    "\n",
    "### Step 3: Cleaning Data\n",
    "Before I performed the cleaning I made a copy of the original data. I documented clearly my cleaning process using the define-code-test framework. The end result of my cleaning process is a high-quality and tidy master pandas DataFrame.\n",
    "\n",
    "### Step 4: Storing Data\n",
    "Here, i saved the gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"\n",
    "\n",
    "### Step 5: Analyzing and Visualizing Data\n",
    "In the Analyzing and Visualizing Data section of my wrangle_act.ipynb Jupyter Notebook, I analyzed and visualized my wrangled data, which include, three separate insights, one labled visualization, and I documented the data used to make each analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
